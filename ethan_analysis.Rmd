---
title: "ethan_analysis"
author: "Ethan Powers"
date: '2022-11-12'
output: html_document
---

```{r}
#install.packages("tidymodels")
#install.packages("fs")
#install.packages("caret")
#install.packages("caTools")
#install.packages("leaps")
#install.packages("glmnet")
#install.packages("pls")
#install.packages("forecast")
#install.packages("plyr")
#install.packages("readr")
#install.packages("repr")
install.packages("kableExtra")
```
```{r, echo=FALSE, message=FALSE, warning=FALSE, results=FALSE}

#setwd("~/Desktop/DSCI/DSCI445/Project")
library(tidyverse)
library(ggplot2)
library(dplyr)
library(caret)
library(leaps)
library(caTools)
library(tidymodels)
library(glmnet)
library(pls)
library(forecast)
library(GGally)
library(plyr)
library(readr)
library(repr)
library(knitr)
library(kableExtra)

set.seed(420)

dataTemp <- read.csv("breast_cancer_diagnostic_data.csv")
datatemp2 <- dataTemp %>% select_if(~ !any(is.na(.)))
dataTot <- datatemp2[,!names(datatemp2) %in% c("id")]

testtemp <- read.csv("test.csv")
testTot <- testtemp[,!names(testtemp) %in% c("id")]

traintemp <- read.csv("training.csv")
trainTot <- traintemp[,!names(traintemp) %in% c("id")]

head(dataTot)
```

```{r}
corr_df <- dataTot[,c('area_worst', 'area_mean', 'concave.points_mean', 'radius_worst')]
#head(corr_df)
ggpairs(corr_df)
```

--------------------------------------------------------------------------------

## area_mean
# Logestic regression

```{r}
#Train
am_lm <- lm(area_mean ~ ., data = trainTot)
pred_amtrain<- predict(am_lm, trainTot)
amtrain_log <- postResample(pred_amtrain, trainTot$area_mean)
amtrain_log
```
```{r}
#Test
pred_amtest <- predict(am_lm, testTot)
amtest_log <- postResample(pred_amtest, testTot$area_mean)
amtest_log
#summary(am_lm)
```

# ridge regression
```{r}
dummy <- dummyVars(area_mean~., data = dataTot[,-1])
x = as.matrix(predict(dummy, newdata = trainTot[,-1]))
y_train = trainTot$area_mean

x_test = as.matrix(predict(dummy, newdata = testTot[,-1]))
y_test = testTot$area_mean

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y_train, alpha = 0, family = 'gaussian', lambda = lambdas)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min

eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))

  
  # Model performance metrics
data.frame(
  RMSE = RMSE,
  Rsquared = R_square)
  
}

# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
amr_train <- eval_results(y_train, predictions_train, trainTot)

# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
amr_test <- eval_results(y_test, predictions_test, testTot)

print(amr_train)
print(amr_test)
```

# lasso
```{r}
lambdas <- 10^seq(2, -3, by = -.1)
lasso_reg <- cv.glmnet(x, y_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 10)

lambda_best <- lasso_reg$lambda.min 
lasso_model <- glmnet(x, y_train, alpha = 1, lambda = lambda_best, standardize = TRUE)

predictions_train <- predict(lasso_model, s = lambda_best, newx = x)
aml_train <- eval_results(y_train, predictions_train, trainTot)

predictions_test <- predict(lasso_model, s = lambda_best, newx = x_test)
aml_test <- eval_results(y_test, predictions_test, testTot)

print(aml_train)
print(aml_test)
```


```{r}
table_am <- as_tibble(rbind(amtrain_log,
      amtest_log,
      amr_train,
      amr_test,
      aml_train,
      aml_test)) %>%
    mutate(model = c('Linear Train Error',  'Linear Test Error','Ridge Train Error', 'Ridge Test Error', 'Lasso Train Error', 'Lasso Test Error')) %>%
    select(model, RMSE, Rsquared)
table_am %>% 
  kbl(digits = 5 ) %>% 
  kable_styling(bootstrap_options = "striped")
```

--------------------------------------------------------------------------------

## Area_worst
# Logestic regression

```{r}
#Test
aw_lm <- lm(area_worst ~ ., data = trainTot)
pred_awtest <- predict(aw_lm, testTot)
awtest_log <- postResample(pred_awtest, testTot$area_worst)
awtest_log
#summary(am_lm)
```

```{r}
#Train
pred_awtrain<- predict(aw_lm, trainTot)
awtrain_log <- postResample(pred_awtrain, trainTot$area_worst)
awtrain_log
```

# ridge regression
```{r}
dummy <- dummyVars(area_worst~., data = dataTot[,-1])
x = as.matrix(predict(dummy, newdata = trainTot[,-1]))
y_train = trainTot$area_worst

x_test = as.matrix(predict(dummy, newdata = testTot[,-1]))
y_test = testTot$area_worst

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y_train, alpha = 0, family = 'gaussian', lambda = lambdas)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min

eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))

  
  # Model performance metrics
data.frame(
  RMSE = RMSE,
  Rsquared = R_square)
  
}

# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
awr_train <- eval_results(y_train, predictions_train, trainTot)

# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
awr_test <- eval_results(y_test, predictions_test, testTot)

print(awr_train)
print(awr_test)
```

# lasso
```{r}
lambdas <- 10^seq(2, -3, by = -.1)
lasso_reg <- cv.glmnet(x, y_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 10)

lambda_best <- lasso_reg$lambda.min 
lasso_model <- glmnet(x, y_train, alpha = 1, lambda = lambda_best, standardize = TRUE)

predictions_train <- predict(lasso_model, s = lambda_best, newx = x)
awl_train <- eval_results(y_train, predictions_train, trainTot)

predictions_test <- predict(lasso_model, s = lambda_best, newx = x_test)
awl_test <- eval_results(y_test, predictions_test, testTot)

print(awl_train)
print(awl_test)
```

```{r}
table_aw <- as_tibble(rbind(awtrain_log,
      awtest_log,
      awr_train,
      awr_test,
      awl_train,
      awl_test)) %>%
    mutate(model = c('Linear Train Error',  'Linear Test Error','Ridge Train Error', 'Ridge Test Error', 'Lasso Train Error', 'Lasso Test Error')) %>%
    select(model, RMSE, Rsquared)
table_aw %>% 
  kbl(digits = 5 ) %>% 
  kable_styling(bootstrap_options = "striped")
```


--------------------------------------------------------------------------------
## concave.points_mean

```{r}
#Train
cvptsm_lm <- lm(concave.points_mean ~ ., data = trainTot)
pred_cvptsm_train<- predict(cvptsm_lm, trainTot)
cvptsm_train_log <- postResample(pred_cvptsm_train, trainTot$concave.points_mean)
cvptsm_train_log
```
```{r}
#Test
pred_cvptsm_test <- predict(cvptsm_lm, testTot)
cvptsm_test_log <- postResample(pred_cvptsm_test, testTot$concave.points_mean)
cvptsm_test_log
#summary(am_lm)
```

# ridge regression
```{r}
dummy <- dummyVars(concave.points_mean~., data = dataTot[,-1])
x = as.matrix(predict(dummy, newdata = trainTot[,-1]))
y_train = trainTot$concave.points_mean

x_test = as.matrix(predict(dummy, newdata = testTot[,-1]))
y_test = testTot$concave.points_mean

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y_train, alpha = 0, family = 'gaussian', lambda = lambdas)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min

eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))

  
  # Model performance metrics
data.frame(
  RMSE = RMSE,
  Rsquared = R_square)
  
}

# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
cvptsmr_train <- eval_results(y_train, predictions_train, trainTot)

# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
cvptsmr_test <- eval_results(y_test, predictions_test, testTot)

print(cvptsmr_train)
print(cvptsmr_test)
```

# lasso
```{r}
lambdas <- 10^seq(2, -3, by = -.1)
lasso_reg <- cv.glmnet(x, y_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 10)

lambda_best <- lasso_reg$lambda.min 
lasso_model <- glmnet(x, y_train, alpha = 1, lambda = lambda_best, standardize = TRUE)

predictions_train <- predict(lasso_model, s = lambda_best, newx = x)
cvptsml_train <- eval_results(y_train, predictions_train, trainTot)

predictions_test <- predict(lasso_model, s = lambda_best, newx = x_test)
cvptsml_test <- eval_results(y_test, predictions_test, testTot)

print(cvptsml_train)
print(cvptsml_test)
```

```{r}
table_am <- as_tibble(rbind(cvptsm_train_log,
      cvptsm_test_log,
      cvptsmr_train,
      cvptsmr_test,
      cvptsml_train,
      cvptsml_test)) %>%
    mutate(model = c('Linear Train Error',  'Linear Test Error','Ridge Train Error', 'Ridge Test Error', 'Lasso Train Error', 'Lasso Test Error')) %>%
    select(model, RMSE, Rsquared)
table_am %>% 
  kbl(digits = 5 ) %>% 
  kable_styling(bootstrap_options = "striped")
```

--------------------------------------------------------------------------------

## Radius Worst

```{r}
#Train
rw_lm <- lm(radius_worst ~ ., data = trainTot)
pred_rw_train<- predict(rw_lm, trainTot)
rw_train_log <- postResample(pred_rw_train, trainTot$radius_worst)
rw_train_log
```
```{r}
#Test
pred_rw_test <- predict(rw_lm, testTot)
rw_test_log <- postResample(pred_rw_test, testTot$radius_worst)
rw_test_log
#summary(am_lm)
```

# ridge regression
```{r}
dummy <- dummyVars(radius_worst~., data = dataTot[,-1])
x = as.matrix(predict(dummy, newdata = trainTot[,-1]))
y_train = trainTot$radius_worst

x_test = as.matrix(predict(dummy, newdata = testTot[,-1]))
y_test = testTot$radius_worst

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y_train, alpha = 0, family = 'gaussian', lambda = lambdas)
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min

eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))

  
  # Model performance metrics
data.frame(
  RMSE = RMSE,
  Rsquared = R_square)
  
}

# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
rwr_train <- eval_results(y_train, predictions_train, trainTot)

# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
rwr_test <- eval_results(y_test, predictions_test, testTot)

print(rwr_train)
print(rwr_test)
```

# lasso
```{r}
lambdas <- 10^seq(2, -3, by = -.1)
lasso_reg <- cv.glmnet(x, y_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 10)

lambda_best <- lasso_reg$lambda.min 
lasso_model <- glmnet(x, y_train, alpha = 1, lambda = lambda_best, standardize = TRUE)

predictions_train <- predict(lasso_model, s = lambda_best, newx = x)
rwl_train <- eval_results(y_train, predictions_train, trainTot)

predictions_test <- predict(lasso_model, s = lambda_best, newx = x_test)
rwl_test <- eval_results(y_test, predictions_test, testTot)

print(rwl_train)
print(rwl_test)
```

```{r}
table_am <- as_tibble(rbind(rw_train_log,
      rw_test_log,
      rwr_train,
      rwr_test,
      rwl_train,
      rwl_test)) %>%
    mutate(model = c('Linear Train Error',  'Linear Test Error','Ridge Train Error', 'Ridge Test Error', 'Lasso Train Error', 'Lasso Test Error')) %>%
    select(model, RMSE, Rsquared)
table_am %>% 
  kbl(digits = 5 ) %>% 
  kable_styling(bootstrap_options = "striped")
```

